[{"title":"About","href":"about","content":"Hi My name is Bart de Goede and I write software for a living Besides that I like a lot of other things such as traveling eating nice food or go for a drink with my friends Most of the posts I write are about things related to tech and programming or anything else I find interesting Find me on GitHubhttpsgithubcombartdegoede LinkedInhttpswwwlinkedincominbartdegoede597a5232 or Twitterhttpstwittercombartdegoede"},{"title":"Searching your Hugo site with Lunr","categories":["hugo","search","lunr","javascript","how-to"],"href":"searching-your-hugo-site-with-lunr","content":"Like many software engineers I figured I needed a blog of sorts because it would give me a place for my own notes on How To Do Things let me have a URL to give people and share my ramblings about Life the Universe and Everything Else with whoever wants to read them Because Im trying to get more familiar with Gohttpsgolangorg I opted to use the awesome Hugohttpsgohugoiohugo framework to build myself a static site hosted on Github Pageshttpspagesgithubcom In my day job I work on our search engine so the first thing that I wanted to have was some basic search functionality for all the blog posts I havent written yet preferably something that I can mess with is extensible and configurable There are three options if you want to add search functionality to a static website each with their pros and cons 1 Thirdparty service ie Google CSE There are a bunch of services that provide basic search widgets for your site such as Google Custom Search Engine CSEhttpscsegooglecomcse Those are difficult to customise break your UI with their Googlestyled widgets and in some cases will display ads on your websitegoogleads 2 Run a serverside search engine You can set up a backend that indexes your data and can process the queries your users submit in the search box on your website The obvious downside is that you throw away all the benefits of having a static site free hosting complex infrastructure 3 Search clientside Having a static side it makes sense to move all the user interaction to the client We depend on the users browser to run Javascriptmyusers and download the searchable data in order to run queries against it but the upside is that you can control how data is processed and how that data is queried Fortunately for us Atwoods Lawhttpsblogcodinghorrorcomtheprincipleofleastpower holds true theres a fulltext search library inspired by LuceneSolr written in Javascript we can use to implement our search engine Lunrjshttpslunrjscom Relevance When thinking about search the most important question is what users want to find This sounds very much like an open door but youd be surprised how often this gets overlooked what are we looking for tweets products the fastest route to a destination who is doing the search lawyers software engineers my mom what do we hope to get out of it money page views In our case were searching blog posts that have titles tags and content in decreasing order of value to relevance queries matching titles should be more important than matches in post contentrelevance Indexing The project folder for my bloggithub looks roughly like this blog Hugo project root folder content this is where the pages I want to be searchable live aboutmd post 20180101firstpostmd 20180115secondpostmd layout partials these contain the templates we need for search searchhtml searchscriptshtml static js search Where we generate the index file vendor lunrjsminjs lunrjs library httpscdnjscomlibrarieslunrjs configtoml Gruntfilejs This will build our index The idea is that we build an index on site generation time and fetch that file when a user loads the page I use Gruntjshttpsgruntjscomgrunttogo to build the index file and some dependencies that make life a little easier Install them with npm npm install savedev grunt string graymatter This is my GruntfilejshttpsgithubcombartdegoedeblogblobmasterGruntfilejs that lives in the root of my project It will walk through the content directory and parse all the markdown files it finds It will parse out title categories and href this will be the reference to the post ie the URL of the page we want to point to from the front matter and the content from the rest of the post It also skips posts that are labeled draft because I dont want the posts Im still working on to already show up in the search results var matter requiregraymatter var S requirestring var CONTENTPATHPREFIX content moduleexports functiongrunt gruntregisterTasksearchindex function gruntlogwritelnBuild pages index var indexPages function var pagesIndex gruntfilerecurseCONTENTPATHPREFIX functionabspath rootdir subdir filename gruntverbosewritelnParse file abspath d processMDFileabspath filename if d undefined pagesIndexpushd return pagesIndex var processMDFile functionabspath filename var content mattergruntfilereadabspath filename if contentdatadraft dont index draft posts return var pageIndex return title contentdatatitle categories contentdatacategories href contentdataslug content ScontentcontenttrimstripTagsstripPunctuations gruntfilewritestaticjssearchindexjson JSONstringifyindexPages gruntlogokIndex built To run this task simply run grunt searchindex in the directory where Gruntfilejs is locateddeploy This will generate a JSON index file looking like this content Hi My name is Bart de Goede and href about title About content Like many software engineers I figured I needed a blog of sorts href Searchingyourhugositewithlunr title Searching your Hugo site with Lunr categories hugo search lunr javascript Querying Now weve built the index we need a way of obtaining it clientside and then query it To do that I have two partials that include the markup for the search input boxhttpsgithubcombartdegoedeblogblobmasterlayoutspartialssearchhtml and the links to the relevant Javascripthttpsgithubcombartdegoedeblogblobmasterlayoutspartialssearchscriptshtml For my blog I have one searchjs filehttpsgithubcombartdegoedeblogblobmasterstaticjssearchsearchjs that will download the index file initialise the UI and run the searches For the sake of readability Ive split up the relevant functions below and added some comments to the code This function fetches the index file weve generated with the Grunt task initialises the relevant fields and then adds the each of the documents to the index The pagesIndex variable will store the documents as we indexed them and the searchIndex variable will store the statistics and data structures we need to rank our documents for a query efficiently function initSearchIndex this file is built by the Grunt task and getJSONjssearchindexjson donefunctiondocuments pagesIndex documents searchIndex lunrfunction thisfieldtitle thisfieldcategories thisfieldcontent thisrefhref This will add all the documents to the index This is different compared to older versions of Lunr where documents could be added after index initialisation for var i 0 i documentslength i thisadddocumentsi failfunctionjqxhr textStatus error var err textStatus error consoleerrorError getting index file err initSearchIndex Then we need to sprinkle some jQuery magic on the input box In my case I want to start searching once a user has typed at least two characters and support a typeahead style of searching so everytime a character is entered I want to empty the current search results if any run the searchSite function with whatever is in the input box and render the results function initUI results posts or whatever element is supposed to hold your results searchkeyupfunction resultsempty only search when query has 2 characters or more var query thisval if querylength 2 return var results searchSitequery renderResultsresults documentreadyfunction initUI The searchSite function will take the querystring the user typed in and build a lunrQuery object and run it against the index stored in the searchIndex variable The lunr index will return a ranked list of refs these are the identifiers we assigned to the documents in the Gruntfile The second part of this method maps these identifiers to the original documents we stored in the pagesIndex variable this function will parse the querystring which will you to run queries like titlelunr search the title field lunr10 boost hits with this term by a factor 10 or lunr2 will match anything within an edit distance of 2 ie losr will also match function simpleSearchSitequerystring return searchIndexsearchquerystringmapfunctionresult return pagesIndexfilterfunctionpage return pagehref resultref 0 I want a typeahead search so if a user types a query like pyth it should show results that contain the word Python rather than just the entire word function searchSitequerystring return searchIndexqueryfunctionq look for an exact match and give that a massive positive boost qtermquerystring usePipeline true boost 100 prefix matches should not use stemming and lower positive boost qtermquerystring usePipeline false boost 10 wildcard lunrQuerywildcardTRAILING mapfunctionresult return pagesIndexfilterfunctionpage return pagehref resultref 0 The snippet above lists two methods The first shows an example of a search using the default lunrIndexsearch method which uses the lunr query syntax In my case I want to support a typeahead search where we show the user results for partial queries too if the user types pyth we should display results that have the word python in the post To do that we tell Lunr to combine two queries the first qterm provides exact matches with a high boost to relevance because we its likely that these matches are relevant to the user the second appends a trailing wildcard to the querytrie providing prefix matches with a lower boost Finally given the ranked list of results containing all pages in the content directory we want to render those somewhere on the page The renderResults method slices the result list to the first ten results creates a link to the appropriate post based on the href and creates a crude snippet based on the 100 first characters of the content function renderResultsresults if resultslength return resultsslice0 10forEachfunctionhit var result resultappend href hithref text hittitle resultappend text hitcontentslice0 100 resultsappendresult This is a pretty naive approach to introducing fulltext search to a static site I use Hugo but this will work with static site generators like Jekyll or Hyde too it completely ignores other languages than English theres support for other languageshttpslunrjscomguideslanguagesupporthtml too let alone non whitespace languages like Chinese and it requires users to download the full index that contains all your searchable pages so it wont scale as nicely if you have thousands of pages For my personal blog though its good enough hugo Its fast its written in Golang it supports fancy themeshttpsthemesgohugoio and its open sourcehttpsgithubcomgohugoiohugo googleads You can make moneyhttpssupportgooglecomadsenseanswer9879visitid16365579053186633953173001859ctxas2hlenrd2reftopic1705820 off theses ads but the question is whether you want to show ads on your personal blog or not myusers Im assuming that the audience thatll land on these pages will have Javascript enabled in their browser relevance In this case Im totally assuming that if words from the query occur in the title or the manually assigned tags of a post are way more relevant than matches in the content of a post if only because theres a lot more words in post content so theres a higher probability of matching any word in the query github Its also on GitHubhttpsgithubcombartdegoedeblog grunttogo A port of this script to Golang is in the works deploy The idea is to run the task before you deploy the latest version of your site In my case I have a deploysh scripthttpsgithubcombartdegoedeblogblobmasterdeploysh that runs Hugo to build my static pages runs grunt searchindex and pushes the result to GitHub trie Lunr uses tries to represent terms internally giving us an efficient way of doing fast prefix lookups"},{"title":"Bloom filters, using bit arrays for recommendations, caches and Bitcoin","categories":["python","bloom filter","how-to"],"href":"bloom-filters-bit-arrays-recommendations-caches-bitcoin","content":"Bloom filters are cool In my experience its a somewhat underestimated data structure that sounds more complex than it actually is In this post Ill go over what they are how they work Ive hacked together an interactive exampleinteractiveexample to help visualise what happens behind the scenes and go over some of their usecases in the wild What is a Bloom filter A Bloom filter is a data structure designed to quickly tell you whether an element is not in a set Whats even nicer it does so within the memory constraints you specify It doesnt actually store the data itself only trimmed down version of it This gives it the desirable property that it has a constant time complexityBigO for both adding a value to the filter and for checking whether a value is present in the filter The cool part is that this is independent of how many elements already in the filter Like with most things that offer great benefits there is a tradeoff Bloom filters are probabilistic in nature On rare occassions it will respond with yes to the question if the element is in the set false positives are a possibility although it will never respond with no if the value is actually present false negatives cant happen You can actually control how rare those occassions are by setting the size of the Bloom filter bit array and the amount of hash functions depending on the amount of elements you expect to addoptimalhashfunctions Also note that you cant remove items from a Bloom filter How does it work An empty Bloom filter is a bit array of a particular size lets call that size m where all the bits are set to 0 In addition there must be a number lets call the number k of hashing functions defined Each of these functions hashes a value to one of the positions in our array m distributing the values uniformly over the array Well do a very simple Python implementationbloomgist of a Bloom filter For simplicitys sake well use a bit arraybitarraydisclaimer with 15 bits m15 and 3 hashing functions k3 for the running example import mmh3 class Bloomfilterobject def initself m15 k3 selfm m selfk k we use a list of Booleans to represent our bit array for simplicity selfbitarray False for i in rangeselfm def addself element def checkself element To add elements to the array our add method needs to run k hashing functions on the input that each will almost randomly pick an index in our bit array Well use the mmh3httpspypipythonorgpypimmh3 library to hash our element and use the amount of hash functions we want to apply as a seed to give us different hashes for each of them Finally we compute the remainder of the hash divided by the size of the bit array to obtain the position we want to setsignedisfalse def addself element Add an element to the filter Murmurhash3 gives us hash values distributed uniformly enough we can use different seeds to represent different hash functions for i in rangeselfk this will give us a number between 0 and m 1 digest mmh3hashelement i signedFalse selfm selfbitarraydigest True In our case m15 and k3 we would set the bits at index 1 7 and 10 to one for the string hello In 1 mmh3hashhello 0 signedFalse 15 Out1 1 In 2 mmh3hashhello 1 signedFalse 15 Out2 7 In 3 mmh3hashhello 2 signedFalse 15 Out3 10 Now to determine if an element is in the bloom filter we apply the same hash functions to the element and see whether the bits at the resulting indices are all 1 If one of them is not 1 then the element has not been added to the filter because otherwise wed see a value of 1 for all hash functions def checkself element To check whether element is in the filter we hash the element with the same hash functions as the add functions using the seed If one of them doesnt occur in our bitarray the element is not in there only a value that hashes to all of the same indices weve already seen before for i in rangeselfk digest mmh3hashelement i signedFalse selfm if selfbitarraydigest False if any of the bits hasnt been set then its not in the filter return False return True You can see how this approach guarantuees that there will be no false negatives but that there might be false positives especially in our toy example with the small bit array the more elements you add to the filter the more likely it gets that the three bits we hash an element to are set other elements running one of the hash functions on the string world will also set the bit at index 6 to 1 In 4 mmh3hashworld 0 signedFalse 15 Out4 7 In 5 mmh3hashworld 1 signedFalse 15 Out5 4 In 6 mmh3hashworld 2 signedFalse 15 Out6 9 We can actually compute the probabilityhttpsenwikipediaorgwikiBloomfilterProbabilityoffalsepositives of our Bloom filter returning a false positive as it is a function of the number of bits used in the bit array divided by the length of the bit array m to the power of hash functions were using k well leave that for a future post though The more values we add the higher the probability of false positives becomes Interactive example To further drive home how Bloom filters work Ive hacked together a Bloom filter in JavaScript that uses the cells in the table below as a bit array to visualise how adding more values will fill up the filter and increase the probability of a false positive a full Bloom filter will always return yes for whatever value you throw at it Add Hash value 1 Hash value 2 Hash value 3 Elements in the filter Probability of false positives 0 Test In Bloom filter What can I use it for Given that a Bloom filter is really good at telling you whether something is in a set or not caching is a prime candidate for using a Bloom filter CDN providers like Akamaiakamairef use it to optimise their disk caches nearly 75 of the URLs that are accessed in their web caches is accessed only once and then never again To prevent caching these onehit wonders and massively saving disk space requirements Akamai uses a Bloom filter to store all URLs that are accessed If a URL is found in the Bloom filter it means it was requested before and should be stored in their disk cache Blogging platform Medium uses Bloom filtershttpsblogmediumcomwhatarebloomfilters1ec2a50c68ffmediumbloom to filter out posts that users have already read from their personalised reading lists They create a Bloom filter for every user and add every article they read to the filter When a reading list is generated they can check the filter whether the user has seen the article The tradeoff for false positives ie an article they havent read before is more than acceptable because in that case the user wont be shown an article that they havent read yet so they will never know Quora does something similar to filter out stories users have seen before and FacebookhttpswwwfacebookcomEngineeringvideos432864835468 and LinkedInhttpsengineeringlinkedincomopensourcecleoopensourcetechnologybehindlinkedinstypeaheadsearch use Bloom filters in their typeahead searches it basically provides a fast and memoryefficient way to filter out documents that cant match on the prefix of the query terms Bitcoin relies strongly on a peertopeer style of communication instead of a clientserver architecture in the examples above Every node in the network is a server and everyone in the network has a copy of everone elses transactions For big beefy servers in a data center thats fine but what if you dont necessarily care about all transactions Think of a mobile wallet application for example you dont want all transactions on the blockchain especially when you have to download them on a mobile connection To address this Bitcoin has an option called Simplified Payment VerificationhttpsenbitcoinitwikiScalabilitySimplifiedpaymentverification SPV which lets your mobile node request only the transactions its interested in ie payments from or to your wallet address The SPV client calculates a Bloom filter for the transactions it cares about so the full node has an efficient way to answer is this client interested in this transation The cost of false positives ie a client is actually not interested in a transaction is minimal because when the client processes the transactions returned by the full node it can simply discard the ones it doesnt care about Closing thoughts There are a lot more applicationshttpswwwquoracomWhatarethebestapplicationsofBloomfilters for Bloom filters out there and I cant list them all here I hope a gave you a whirlwind overview of how Bloom filters work and how they might be useful to you Feel free to drop me a lineabout or comment below if you have nice examples of where theyre used or if you have any feedback comments or just want to say hi BigO The runtime for both inserting and checking is defined by the number of hash functions k we have to execute So Ok Space complexity is more difficult to quantify because that depends on how many false positives youre willing to tolerate allocating more space will lower the false positive rate optimalhashfunctions Going over the math is a bit much for this post so check WikipediahttpsenwikipediaorgwikiBloomfilterOptimalnumberofhashfunctions for all the formulas bloomgist Full implementation on GitHubhttpsgistgithubcombartdegoede42ef7a265d946a9a75617a89ecbaf674 bitarraydisclaimer Our implementation wont use an actual bit array but a Python list containing Booleans for the sake of readability signedisfalse Note that theres a slight difference between the Python and Javascript Murmurhash implementation in the libraries Ive used the Javascript library I usedhttpspidgithubiomurmurHash3js returns a 32 bit unsigned integer where the Python libraryhttpsgithubcomhajimesmmh3 returns a 32 bit signed integer by default To keep the Python example consistent with the Javascript I opted to use unsigned integers there too there is no impact for the working of the Bloom filter akamairef Maggs Bruce M Sitaraman Ramesh K July 2015 Algorithmic nuggets in content delivery SIGCOMM Computer Communication Review New York NY USA ACM 45 3 5266 doi10114528057892805800httpsdoiorg1011452F28057892805800 mediumbloom Read the article Its really good"},{"title":"Free SSL with a custom domain on GitHub Pages","categories":["ssl","hugo","how-to","gh-pages","https"],"href":"free-ssl-on-github-pages-with-a-custom-domain","content":"GitHub Pageshttpspagesgithubcom is pretty awesome It lets you push a bunch of static HTML andor CSS and Javascript to a GitHub repository and theyll host and serve it for you For free You basically set up a specific repository you have to name it githubio you push your HTML there and they will be available at httpsgithubio Did I mention that this is free While you can perfectly write and push HTML files straight to your GitHub repository theres a whole bunchhttpsjekyllrbcomdocshome of open source statichttpsgohugoio sitehttpshydegithubio generators available that provide a structured way of organising content in formats Markdownhttpsdaringfireballnetprojectsmarkdown that are easier to work withstaticsitegenerators GitHub even supports one of them Jekyllhttpsgithubcomjekylljekyll out of the box so you can just push your project as is and theyll take care of building of your HTML toojekyllvshugo You can even set up your own custom domain Register your domain at your favourite registrar and change a setting for your repository GitHub settingsimg20180328freesslongithubpageswithacustomdomaingithubrepositorysettingspng There you fill out the custom domain you want your site to be available at in my case thats bartdegoede GitHub custom domain settingsimg20180328freesslongithubpageswithacustomdomaingithubpagessettingscustomdomainpng Before you rush off to your registrar to point your domain or subdomain in my caseconfession make sure you add a CNAME file to the root of your repository The CNAME filehttpsgithubcombartdegoedebartdegoedegithubioblobmasterCNAME should contain the URL your website should be displaying in the browser this is important for redirects In my case the file contains bartdegoede because thats the URL I want my site to be published under Setting up CloudFlare and SSL Then all you need to do is add a CNAME entry to your domain settings settings Right Well yes and no Yes setting up a CNAME DNS record will get your website working under the proper URL it might take a while for the DNS change to propagate Registrar CNAMEimg20180328freesslongithubpageswithacustomdomainregistrarcnamepng However serving your static files from GitHub under your own domain name does pose a problem GitHub Pages only supports SSL for the githubio domain not for custom domains they have a wildcard certificate for their own domain but supporting HTTPS on custom domains is not trivialopengithubissue That means that your website cant take advantage of HTTP2 speedupshttpswwwmnotnetblog20140104strengtheninghttpapersonalview it will have negative impact on your Google rankinghttpswebmastersgoogleblogcom201408httpsasrankingsignalhtml Chromehttpsdevelopersgooglecomwebupdates201610avoidnotsecurewarn will show your visitors that your website is not securehttpssecuritygoogleblogcom201609movingtowardsmoresecurewebhtml and even for your static site with fancy Javascript featureshttpsbartdegoedesearchingyourhugositewithlunr you do want to protect your users when theyre reading your posts on unsecured WiFi networks CloudFlare Fortunately theres a way to get this coveted green secure lock on your static website CloudFlarehttpswwwcloudflarecomcloudflare provides the free feature Universal SSL that will allow your users to access your website over SSL Sign up for a free account and enter the nonSSLized domain name of your website in their scanning tool CloudFlare setupimg20180328freesslongithubpageswithacustomdomaincloudflarepng CloudFlare will fetch your current DNS configuration and will provide you with instructions on how to enable CloudFlare for your subdomains The idea is that CloudFlare will act as a proxy between your GitHub hosted site and the user This will allow them to encrypt traffic between their servers and your users the traffic between GitHub and CloudFlare is also encrypted but doesnt require you to install an SSL certificate on the GitHub servers added bonus is that they can cache your content on servers close to your visitors increasing the page speed of your website Enable CloudFlare for the subdomain youre hosting your website on CloudFlare DNSimg20180328freesslongithubpageswithacustomdomaincloudflarednspng Enabling SSL CloudFlares Universal SSL lets you provide your websites users with a valid signed SSL certificate Theres several configuration options for Universal SSL find it in the Crypto tab and make sure your SSL mode is set to Full SSL but not Full SSL Strict CloudFlare DNSimg20180328freesslongithubpageswithacustomdomaincloudflaresslpng Do note it may take a while up to 24 hours for CloudFlare to set you up with your SSL certificates They will send you an email once theyre provisioned and ready to go Next create a Page Rule Page rules are surprisingly rules that apply to a page or a collection of pages These rules can do a lot of cool things such as automatically obfuscating emails on the page control cache settings or add geolocation information to the requests The rule youre looking for is Always Use HTTPS which will enforce all requests for pages matching the URL pattern you provide to use SSL CloudFlare pageruleimg20180328freesslongithubpageswithacustomdomaincloudflarepagerulepng In my case I only have one URL for my website However if you use the www subdomain ie wwwexamplecom you might want to add a Page Rule that redirects users that type examplecom to wwwexamplecom where you enforce HTTPS to ensure all users benefit from encrypted requests However if you add more Page Rules make sure that the HTTPS rule is the primary first page rule Only one rule will trigger per URL so youll want to make sure that this one is listed first Profit Right This article has gotten quite meaty for the steps you have to follow so if youre looking for a more concise set of steps this Gist by cvanhttpsgithubcomcvan is great Theres a lot more you can do with CloudFlare and your static site you could set up caching on CloudFlares content distribution network for example but be aware that even though youve encrypted your traffic you should still be carefulhttpshelpgithubcomarticleswhatisgithubpages in submitting sensitive data to thirdparty APIs with Javascript GitHub Pages sites shouldnt be used for sensitive transactions like sending passwords or credit card numbers Your websites source code is publicly available in your GitHub repository so be mindful of any scripts and content you publish there staticsitegenerators I use Hugohttpsgohugoio for this website which is written in Golang fast and easy are keywords I like Theres a lothttpswwwstaticgencom of different static site generatorshttpsmylesgithubioawesomestaticgenerators out there each with their own focuses advantages and tradeoffs jekyllvshugo In my setup I have two separatehttpsgithubcombartdegoedeblog repositorieshttpsgithubcombartdegoedebartdegoedegithubio where I maintain the Hugo project structure in one the blog repository and build and push the static files to the other the bartdegoedegithubio repository What I like about that is that it gives me a deploy stephttpsgithubcombartdegoedeblogblobmasterdeploysh so I dont accidentally push something thats not finished yet confession Skipping this step took me a lot longer to figure out than Im willing to admit opengithubissue Theres been disscusions about this for a whilehttpsgithubcomisaacsgithubissues156 cloudflare CloudFlare is a company that provides a contentdelivery network CDNhttpsenwikipediaorgwikiContentdeliverynetwork DDoShttpsenwikipediaorgwikiDenialofserviceattackDistributedattack protection services DNS and a whole slew of other services for websites"},{"title":"Free SSL on Github Pages with a custom domain: Part 2 - Let's Encrypt","categories":["ssl","hugo","how-to","gh-pages","https","lets-encrypt"],"href":"github-pages-and-lets-encrypt","content":"GitHub Pageshttpspagesgithubcom has just become even more awesome Since yesterdayyesterday GitHub Pages supports HTTPS for custom domainshttpsbloggithubcom20180501githubpagescustomdomainshttps And yes it is still free Lets Encrypt GitHub has partnered with Lets Encrypthttpsletsencryptorg which is a free open and automated certificate authority CA It is run by the Internet Security Research Group ISRGhttpsletsencryptorgisrg which is a public benefit corporationpbccalifornia fundedhttpsletsencryptorgsponsors by donations and a bunch of large corporations and nonprofits The goal of this initiative is to secure the web by making it very easy to obtain a free trusted SSL certificate Moreover it lets web servers run a piece of software that not only gets a valid SSL certificate but will also configure your web server and automatically renew the certificate when it expires How does it do that It works by running a bit of software on your web server a certificate management agent This agent software has two tasks it proves to the Lets Encrypt certificate authority that it controls the domain and it requests renews and revokes certificates for the domain it controls Validating a domain Similar to a traditional process of obtaining a certificate for a domain where you create an account with the CA and add domains you control the certificate management agent needs to perform a test to prove that it controls the domain The agent will ask the Lets Encrypt CA what it needs to do to prove that it is effectively in control of the domain The CA will look at the domain and issue one or more challenges to the agent it needs to complete to prove that it has control over the domain For example it can ask the agent to provision a particular DNS record under the domain or make an HTTP resource available under a particular URL With these challenges it provides the agent with a noncehttpsenwikipediaorgwikiCryptographicnonce some random number that can only be used once for verification purposes In the image above the agent creates a file on a specified path on the web server in this case on httpsexamplecom8303 It creates a key pair it will use to identify itself with the CA and signs the nonce received from the CA with the private key Then it notifies the CA that it has completed the challenge by sending back the signed nonce and is ready for validation The CA then validates the completion of the challenge by attempting to download the file from the web server and verify that it contains the expected content If the signed nonce is valid and the challenge is completed successfully the agent identified by the public key is officially authorized to manage valid SSL certificates for the domain Certificate management So what does that mean By having validated the agent by its public key the CA can now validate that messages sent to the CA are actually sent by the certificate management agent It can send a Certificate Signing Request CSRhttptoolsietforghtmlrfc2986 to the CA to request it to issue a SSL certificate for the domain signed with the authorized key Lets Encrypt will only have to validate the signatures and if those check out a certificate will be issued Lets Encrypt will add the certificate to the appropriate channels so that browsers will know that the CA has validated the certificate and will display that coveted green lock to your users So GitHub Pages Right thats how we got started The awesome thing about Lets Encrypt is that it is automated so all this handshaking and verifying happens behind the scenes without you having to be involved In the previous post we saw how to set up a CNAME filehttpsgithubcombartdegoedebartdegoedegithubioblobmasterCNAME for your custom domain Thats it Done Works out of the box Optionally you can enforce HTTPShttpshelpgithubcomarticlessecuringyourgithubpagessitewithhttps in the settings of your repository This will upgrade all users requesting stuff from your site over HTTP to be automatically redirected to HTTPS If you use A records to route traffic to your website you need to update your DNS settingshttpshelpgithubcomarticlessettingupanapexdomain at your registrar These IP addresses are new and have an added benefit of putting your static site behind a CDN just like we did with Cloudflare in the previous post SSL all the things Lets Encrypt makes securing the web easy More and more websiteshttpsletsencryptorgstats are served over HTTPS only so it is getting increasingly difficult for script kiddies to sniff your web traffichttpsmotherboardvicecomenusarticlejpgmxphowtogofrom0tosniffingpacketsin10minutes on free WiFi networks Moreover they provide this service worldwide to anyone for free Help them help you and the rest of the world and buy them a coffeehttpsletsencryptorgdonate yesterday At time of writing yesterday is May 1 2018 pbccalifornia One in CaliforniahttpsenwikipediaorgwikiPublicbenefitcorporationCalifornia to be specific"},{"title":"Custom OpenSearch: search from your URL bar","categories":["search","opensearch","how-to"],"href":"tab-plus-search-from-your-url-bar-with-opensearch","content":"Almost all modern browsers enable websites to customize the builtin search feature to let the user access their search features directly without going to your website first and finding the search input box If your website has search functionality accessible through a basic GET request its surprisingly simple to enable this for your website too Some browsers do it automatically If your users are on Chrome chances are this already works Chromium tries really hardhttpsdevchromiumorgtabtosearch to figure out where your search page is and how to access it A strong hint you can give it is to change the type of the element to searchinput The name attribute gives the browser a hint as to what HTTP parameter will hold the query it is a good idea to configure your Google Analyticshttpssupportgooglecomanalyticsanswer1012264 to pick this up as well This will let the browser add some nice UI elements to the search input box like a small x button on the right to clear the search input in Safari and Chrome Enabling the autocapitalize autocorrect and autocomplete attributes will instruct your browser to modify and correct the user input even further think of the iOS autocorrect feature for example Word of warning Because once upon a time applecomhttpswwwapplecom relied on the type attribute to give their search box a more Maclike feel Safari will basically ignore any CSShttpdiveintohtml5infoformshtmltypesearch applied to elements If you need Safari to treat your search field like any other input field for display purposes you can add the following to your CSS inputtypesearch webkitappearance textfield This will let you apply your own styles to the input box Others dont Not all browsers do this out of the box so you need to provide them with a more formalized configuration Most browsers find out about the search functionality of a website through an OpenSearch XML file that directs them to the right page OpenSearch OpenSearchhttpsenwikipediaorgwikiOpenSearch is a standard that was developed by A9httpsenwikipediaorgwikiA9com an Amazon subsidiary developing search engine and search advertising technology and has been around since Jeff Bezos unveiled it in 2005 at a conference on emerging technologies It is nothing more than an XML specification that lets a website describe a search engine for itself and where a user or browser might find and use it Firefox Chrome Edge Internet Explorer and Safari all support the OpenSearch standard with Firefox even supporting featureshttpsdevelopermozillaorgenUSdocsWebOpenSearch that are not in the standard such as search suggestions XML All you need is a small XML file Below is an example of the one we have at workhttpswwwscribdcomopensearchxml Scribdcom Scribds mission is to create the worlds largest open library of documents Search it httpswwwscribdcomfaviconico It provides a theres a element too thats mostly used for aggregators or automatically generated search plugins a of what the search will let you do and most importantly the where you can do it It tells the browser theres a texthtml page that can process an HTTP GET request and has a template for the browser searchTerms will be interpolated with the query terms the user will type in the browser You need to host this file somewhere with the rest of your web pages But what if you dont have a dedicated search engine for your website Well just use Google Replace the value of the template attribute with something like thisurl This will redirect your user to the Google search results but those will only display matches from content on your site Thats a lot cheaper than employing a bunch of engineers to build and maintain a custom search engine Turn on autodiscovery Now we need to activate the automatic discovery of search engines in the browsers of your users That sounds a lot cooler and more complicated than it actually is the only thing you have to do is provide a somewhere in the of your webpages This will alert browsers that load the page that there is a search feature available described in the linked XML file Make sure your OpenSearch XML file is available and can be loaded from your webserver and refresh the page containing the This will tell the browser where to look and enable custom search The OpenSearch specification supports a lot more featureshttpsgithubcomdewittopensearchblobmasteropensearch11draft6md than this ranging from to help plugins generated from these standardized descriptions be found better in search plugin aggregatorshttpsaddonsmozillaorgenUSfirefoxsearchtools what the search engine supports or whether the search results may contain There are many ways to configure and customize OpenSearch that go way beyond the basic example described here but for my little blog this is more than enough input The other attributes are to disenable featureshttpsdevelopermozillaorgenUSdocsWebOpenSearch certain other browsers like Safari have that automatically correct what you type into the search box url Yes you could absolutely point your search input to my website but thats not a requirement "}]