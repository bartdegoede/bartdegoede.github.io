[{"title":"About","href":"about","content":"Hi My name is Bart de Goede and I write software for a living Besides that I like a lot of other things such as traveling eating nice food or go for a drink with my friends Find me on GitHubhttpsgithubcombartdegoede LinkedInhttpswwwlinkedincominbartdegoede597a5232 or Twitterhttpstwittercombartdegoede"},{"title":"Searching your Hugo site with Lunr","categories":["hugo","search","lunr","javascript"],"href":"searching-your-hugo-site-with-lunr","content":"Like many software engineers I figured I needed a blog of sorts because it would give me a place for my own notes on How To Do Things let me have a URL to give people and share my ramblings about Life the Universe and Everything Else with whoever wants to read them Because Im trying to get more familiar with Gohttpsgolangorg I opted to use the awesome Hugohttpsgohugoiohugo framework to build myself a static site hosted on Github Pageshttpspagesgithubcom In my day job I work on our search engine so the first thing that I wanted to have was some basic search functionality for all the blog posts I havent written yet preferably something that I can mess with is extensible and configurable There are three options if you want to add search functionality to a static website each with their pros and cons 1 Thirdparty service ie Google CSE There are a bunch of services that provide basic search widgets for your site such as Google Custom Search Engine CSEhttpscsegooglecomcse Those are difficult to customise break your UI with their Googlestyled widgets and in some cases will display ads on your websitegoogleads 2 Run a serverside search engine You can set up a backend that indexes your data and can process the queries your users submit in the search box on your website The obvious downside is that you throw away all the benefits of having a static site free hosting complex infrastructure 3 Search clientside Having a static side it makes sense to move all the user interaction to the client We depend on the users browser to run Javascriptmyusers and download the searchable data in order to run queries against it but the upside is that you can control how data is processed and how that data is queried Fortunately for us Atwoods Lawhttpsblogcodinghorrorcomtheprincipleofleastpower holds true theres a fulltext search library inspired by LuceneSolr written in Javascript we can use to implement our search engine Lunrjshttpslunrjscom Relevance When thinking about search the most important question is what users want to find This sounds very much like an open door but youd be surprised how often this gets overlooked what are we looking for tweets products the fastest route to a destination who is doing the search lawyers software engineers my mom what do we hope to get out of it money page views In our case were searching blog posts that have titles tags and content in decreasing order of value to relevance queries matching titles should be more important than matches in post contentrelevance Indexing The project folder for my bloggithub looks roughly like this blog Hugo project root folder content this is where the pages I want to be searchable live aboutmd post 20180101firstpostmd 20180115secondpostmd layout partials these contain the templates we need for search searchhtml searchscriptshtml static js search Where we generate the index file vendor lunrjsminjs lunrjs library httpscdnjscomlibrarieslunrjs configtoml Gruntfilejs This will build our index The idea is that we build an index on site generation time and fetch that file when a user loads the page I use Gruntjshttpsgruntjscomgrunttogo to build the index file and some dependencies that make life a little easier Install them with npm npm install savedev grunt string graymatter This is my GruntfilejshttpsgithubcombartdegoedeblogblobmasterGruntfilejs that lives in the root of my project It will walk through the content directory and parse all the markdown files it finds It will parse out title categories and href this will be the reference to the post ie the URL of the page we want to point to from the front matter and the content from the rest of the post It also skips posts that are labeled draft because I dont want the posts Im still working on to already show up in the search results var matter requiregraymatter var S requirestring var CONTENTPATHPREFIX content moduleexports functiongrunt gruntregisterTasksearchindex function gruntlogwritelnBuild pages index var indexPages function var pagesIndex gruntfilerecurseCONTENTPATHPREFIX functionabspath rootdir subdir filename gruntverbosewritelnParse file abspath d processMDFileabspath filename if d undefined pagesIndexpushd return pagesIndex var processMDFile functionabspath filename var content mattergruntfilereadabspath filename if contentdatadraft dont index draft posts return var pageIndex return title contentdatatitle categories contentdatacategories href contentdataslug content ScontentcontenttrimstripTagsstripPunctuations gruntfilewritestaticjssearchindexjson JSONstringifyindexPages gruntlogokIndex built To run this task simply run grunt searchindex in the directory where Gruntfilejs is locateddeploy This will generate a JSON index file looking like this content Hi My name is Bart de Goede and href about title About content Like many software engineers I figured I needed a blog of sorts href Searchingyourhugositewithlunr title Searching your Hugo site with Lunr categories hugo search lunr javascript Querying Now weve built the index we need a way of obtaining it clientside and then query it To do that I have two partials that include the markup for the search input boxhttpsgithubcombartdegoedeblogblobmasterlayoutspartialssearchhtml and the links to the relevant Javascripthttpsgithubcombartdegoedeblogblobmasterlayoutspartialssearchscriptshtml For my blog I have one searchjs filehttpsgithubcombartdegoedeblogblobmasterstaticjssearchsearchjs that will download the index file initialise the UI and run the searches For the sake of readability Ive split up the relevant functions below and added some comments to the code This function fetches the index file weve generated with the Grunt task initialises the relevant fields and then adds the each of the documents to the index The pagesIndex variable will store the documents as we indexed them and the searchIndex variable will store the statistics and data structures we need to rank our documents for a query efficiently function initSearchIndex this file is built by the Grunt task and getJSONjssearchindexjson donefunctiondocuments pagesIndex documents searchIndex lunrfunction thisfieldtitle thisfieldcategories thisfieldcontent thisrefhref This will add all the documents to the index This is different compared to older versions of Lunr where documents could be added after index initialisation for var i 0 i documentslength i thisadddocumentsi failfunctionjqxhr textStatus error var err textStatus error consoleerrorError getting index file err initSearchIndex Then we need to sprinkle some jQuery magic on the input box In my case I want to start searching once a user has typed at least two characters and support a typeahead style of searching so everytime a character is entered I want to empty the current search results if any run the searchSite function with whatever is in the input box and render the results function initUI results posts or whatever element is supposed to hold your results searchkeyupfunction resultsempty only search when query has 2 characters or more var query thisval if querylength 2 return var results searchSitequery renderResultsresults documentreadyfunction initUI The searchSite function will take the querystring the user typed in and build a lunrQuery object and run it against the index stored in the searchIndex variable The lunr index will return a ranked list of refs these are the identifiers we assigned to the documents in the Gruntfile The second part of this method maps these identifiers to the original documents we stored in the pagesIndex variable this function will parse the querystring which will you to run queries like titlelunr search the title field lunr10 boost hits with this term by a factor 10 or lunr2 will match anything within an edit distance of 2 ie losr will also match function simpleSearchSitequerystring return searchIndexsearchquerystringmapfunctionresult return pagesIndexfilterfunctionpage return pagehref resultref 0 I want a typeahead search so if a user types a query like pyth it should show results that contain the word Python rather than just the entire word function searchSitequerystring return searchIndexqueryfunctionq look for an exact match and give that a massive positive boost qtermquerystring usePipeline true boost 100 prefix matches should not use stemming and lower positive boost qtermquerystring usePipeline false boost 10 wildcard lunrQuerywildcardTRAILING mapfunctionresult return pagesIndexfilterfunctionpage return pagehref resultref 0 The snippet above lists two methods The first shows an example of a search using the default lunrIndexsearch method which uses the lunr query syntax In my case I want to support a typeahead search where we show the user results for partial queries too if the user types pyth we should display results that have the word python in the post To do that we tell Lunr to combine two queries the first qterm provides exact matches with a high boost to relevance because we its likely that these matches are relevant to the user the second appends a trailing wildcard to the querytrie providing prefix matches with a lower boost Finally given the ranked list of results containing all pages in the content directory we want to render those somewhere on the page The renderResults method slices the result list to the first ten results creates a link to the appropriate post based on the href and creates a crude snippet based on the 100 first characters of the content function renderResultsresults if resultslength return resultsslice0 10forEachfunctionhit var result resultappend href hithref text hittitle resultappend text hitcontentslice0 100 resultsappendresult This is a pretty naive approach to introducing fulltext search to a static site I use Hugo but this will work with static site generators like Jekyll or Hyde too it completely ignores other languages than English theres support for other languageshttpslunrjscomguideslanguagesupporthtml too let alone non whitespace languages like Chinese and it requires users to download the full index that contains all your searchable pages so it wont scale as nicely if you have thousands of pages For my personal blog though its good enough hugo Its fast its written in Golang it supports fancy themeshttpsthemesgohugoio and its open sourcehttpsgithubcomgohugoiohugo googleads You can make moneyhttpssupportgooglecomadsenseanswer9879visitid16365579053186633953173001859ctxas2hlenrd2reftopic1705820 off theses ads but the question is whether you want to show ads on your personal blog or not myusers Im assuming that the audience thatll land on these pages will have Javascript enabled in their browser relevance In this case Im totally assuming that if words from the query occur in the title or the manually assigned tags of a post are way more relevant than matches in the content of a post if only because theres a lot more words in post content so theres a higher probability of matching any word in the query github Its also on GitHubhttpsgithubcombartdegoedeblog grunttogo A port of this script to Golang is in the works deploy The idea is to run the task before you deploy the latest version of your site In my case I have a deploysh scripthttpsgithubcombartdegoedeblogblobmasterdeploysh that runs Hugo to build my static pages runs grunt searchindex and pushes the result to GitHub trie Lunr uses tries to represent terms internally giving us an efficient way of doing fast prefix lookups"}]